{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMNu7Jg5troY"
      },
      "source": [
        "## Positional Encoding\n",
        "\n",
        "This notebook will code positional encoding for Transformer neural networks with pytrch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "H3iqZxn20a7m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "max_sequence_length = 10\n",
        "d_model = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aUNCBlKvxew"
      },
      "source": [
        "$$\n",
        "PE(\\text{position}, 2i) = \\sin\\bigg( \\frac{ \\text{position} }{10000^\\frac{2i}{d_{model}}} \\bigg)\n",
        "$$\n",
        "\n",
        "$$\n",
        "PE(\\text{position}, 2i+1) = \\cos\\bigg( \\frac{ \\text{position} }{10000^\\frac{2i}{d_{model}}} \\bigg)\n",
        "$$\n",
        "\n",
        "We can rewrite these as\n",
        "\n",
        "$$\n",
        "PE(\\text{position}, i) = \\sin\\bigg( \\frac{ \\text{position} }{10000^\\frac{i}{d_{model}}} \\bigg) \\text{ when i is even}\n",
        "$$\n",
        "\n",
        "$$\n",
        "PE(\\text{position}, i) = \\cos\\bigg( \\frac{ \\text{position} }{10000^\\frac{i-1}{d_{model}}} \\bigg) \\text{ when i is odd}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3SWE1Nxwo-D",
        "outputId": "5d9482c7-79ad-46cc-ce14-8e7ad7e335b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0.,  2.,  4.,  6.,  8., 10., 12., 14., 16., 18., 20., 22., 24., 26.,\n",
              "        28., 30., 32., 34., 36., 38., 40., 42., 44., 46., 48., 50., 52., 54.,\n",
              "        56., 58., 60., 62.])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "even_i = torch.arange(0, d_model, 2).float()\n",
        "even_i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-RWR30KxdLM",
        "outputId": "123b4f15-8cba-4eb7-9f5d-faabe2dbc286"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1.0000e+00, 1.3335e+00, 1.7783e+00, 2.3714e+00, 3.1623e+00, 4.2170e+00,\n",
              "        5.6234e+00, 7.4989e+00, 1.0000e+01, 1.3335e+01, 1.7783e+01, 2.3714e+01,\n",
              "        3.1623e+01, 4.2170e+01, 5.6234e+01, 7.4989e+01, 1.0000e+02, 1.3335e+02,\n",
              "        1.7783e+02, 2.3714e+02, 3.1623e+02, 4.2170e+02, 5.6234e+02, 7.4989e+02,\n",
              "        1.0000e+03, 1.3335e+03, 1.7783e+03, 2.3714e+03, 3.1623e+03, 4.2170e+03,\n",
              "        5.6234e+03, 7.4989e+03])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "even_denominator = torch.pow(10000, even_i/d_model)\n",
        "even_denominator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iITvtjTt6jO-",
        "outputId": "2a9f433f-14b6-4a42-fcb2-4b896e215de0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 1.,  3.,  5.,  7.,  9., 11., 13., 15., 17., 19., 21., 23., 25., 27.,\n",
              "        29., 31., 33., 35., 37., 39., 41., 43., 45., 47., 49., 51., 53., 55.,\n",
              "        57., 59., 61., 63.])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "odd_i = torch.arange(1, d_model, 2).float()\n",
        "odd_i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAIVnPLJ1JYC",
        "outputId": "67ca824f-82b1-41d8-fac5-84ff84999349"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1.0000e+00, 1.3335e+00, 1.7783e+00, 2.3714e+00, 3.1623e+00, 4.2170e+00,\n",
              "        5.6234e+00, 7.4989e+00, 1.0000e+01, 1.3335e+01, 1.7783e+01, 2.3714e+01,\n",
              "        3.1623e+01, 4.2170e+01, 5.6234e+01, 7.4989e+01, 1.0000e+02, 1.3335e+02,\n",
              "        1.7783e+02, 2.3714e+02, 3.1623e+02, 4.2170e+02, 5.6234e+02, 7.4989e+02,\n",
              "        1.0000e+03, 1.3335e+03, 1.7783e+03, 2.3714e+03, 3.1623e+03, 4.2170e+03,\n",
              "        5.6234e+03, 7.4989e+03])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "even_denominator = torch.pow(10000, (odd_i - 1)/d_model)\n",
        "even_denominator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBtyLN2NAtEC"
      },
      "source": [
        "`even_denominator` and `odd_denominator` are the same! So we can just do one of these actions and call the resulting variable `denominator`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IyjRI1imBA3F"
      },
      "outputs": [],
      "source": [
        "denominator = even_denominator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WwxxoNSN-me9"
      },
      "outputs": [],
      "source": [
        "position = torch.arange(max_sequence_length, dtype=torch.float).reshape(max_sequence_length, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nfvUzG8-rMK",
        "outputId": "3bc44cf5-0c38-43ae-bee2-7cd86f078601"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [1.],\n",
              "        [2.],\n",
              "        [3.],\n",
              "        [4.],\n",
              "        [5.],\n",
              "        [6.],\n",
              "        [7.],\n",
              "        [8.],\n",
              "        [9.]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XEm-9niG4VEl"
      },
      "outputs": [],
      "source": [
        "even_PE = torch.sin(position / denominator)\n",
        "odd_PE = torch.cos(position / denominator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uqfc01YJ43w6",
        "outputId": "b151d8fe-ce1c-4bfc-bb57-1e3ec54aae49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00],\n",
              "        [ 8.4147e-01,  6.8156e-01,  5.3317e-01,  4.0931e-01,  3.1098e-01,\n",
              "          2.3492e-01,  1.7689e-01,  1.3296e-01,  9.9833e-02,  7.4919e-02,\n",
              "          5.6204e-02,  4.2157e-02,  3.1618e-02,  2.3712e-02,  1.7782e-02,\n",
              "          1.3335e-02,  9.9998e-03,  7.4989e-03,  5.6234e-03,  4.2170e-03,\n",
              "          3.1623e-03,  2.3714e-03,  1.7783e-03,  1.3335e-03,  1.0000e-03,\n",
              "          7.4989e-04,  5.6234e-04,  4.2170e-04,  3.1623e-04,  2.3714e-04,\n",
              "          1.7783e-04,  1.3335e-04],\n",
              "        [ 9.0930e-01,  9.9748e-01,  9.0213e-01,  7.4690e-01,  5.9113e-01,\n",
              "          4.5669e-01,  3.4821e-01,  2.6355e-01,  1.9867e-01,  1.4942e-01,\n",
              "          1.1223e-01,  8.4239e-02,  6.3203e-02,  4.7410e-02,  3.5558e-02,\n",
              "          2.6667e-02,  1.9999e-02,  1.4997e-02,  1.1247e-02,  8.4338e-03,\n",
              "          6.3245e-03,  4.7427e-03,  3.5566e-03,  2.6670e-03,  2.0000e-03,\n",
              "          1.4998e-03,  1.1247e-03,  8.4339e-04,  6.3246e-04,  4.7427e-04,\n",
              "          3.5566e-04,  2.6670e-04],\n",
              "        [ 1.4112e-01,  7.7827e-01,  9.9325e-01,  9.5363e-01,  8.1265e-01,\n",
              "          6.5290e-01,  5.0854e-01,  3.8947e-01,  2.9552e-01,  2.2308e-01,\n",
              "          1.6790e-01,  1.2617e-01,  9.4726e-02,  7.1081e-02,  5.3323e-02,\n",
              "          3.9995e-02,  2.9995e-02,  2.2495e-02,  1.6869e-02,  1.2651e-02,\n",
              "          9.4867e-03,  7.1141e-03,  5.3348e-03,  4.0006e-03,  3.0000e-03,\n",
              "          2.2497e-03,  1.6870e-03,  1.2651e-03,  9.4868e-04,  7.1141e-04,\n",
              "          5.3348e-04,  4.0006e-04],\n",
              "        [-7.5680e-01,  1.4154e-01,  7.7847e-01,  9.9328e-01,  9.5358e-01,\n",
              "          8.1257e-01,  6.5283e-01,  5.0847e-01,  3.8942e-01,  2.9548e-01,\n",
              "          2.2304e-01,  1.6788e-01,  1.2615e-01,  9.4713e-02,  7.1071e-02,\n",
              "          5.3316e-02,  3.9989e-02,  2.9991e-02,  2.2492e-02,  1.6867e-02,\n",
              "          1.2649e-02,  9.4854e-03,  7.1131e-03,  5.3341e-03,  4.0000e-03,\n",
              "          2.9996e-03,  2.2494e-03,  1.6868e-03,  1.2649e-03,  9.4855e-04,\n",
              "          7.1131e-04,  5.3341e-04],\n",
              "        [-9.5892e-01, -5.7113e-01,  3.2394e-01,  8.5890e-01,  9.9995e-01,\n",
              "          9.2676e-01,  7.7653e-01,  6.1844e-01,  4.7943e-01,  3.6622e-01,\n",
              "          2.7748e-01,  2.0929e-01,  1.5746e-01,  1.1829e-01,  8.8797e-02,\n",
              "          6.6627e-02,  4.9979e-02,  3.7486e-02,  2.8113e-02,  2.1083e-02,\n",
              "          1.5811e-02,  1.1857e-02,  8.8913e-03,  6.6676e-03,  5.0000e-03,\n",
              "          3.7495e-03,  2.8117e-03,  2.1085e-03,  1.5811e-03,  1.1857e-03,\n",
              "          8.8914e-04,  6.6676e-04],\n",
              "        [-2.7942e-01, -9.7740e-01, -2.3037e-01,  5.7403e-01,  9.4715e-01,\n",
              "          9.8907e-01,  8.7574e-01,  7.1743e-01,  5.6464e-01,  4.3491e-01,\n",
              "          3.3104e-01,  2.5033e-01,  1.8860e-01,  1.4180e-01,  1.0649e-01,\n",
              "          7.9926e-02,  5.9964e-02,  4.4978e-02,  3.3734e-02,  2.5299e-02,\n",
              "          1.8973e-02,  1.4228e-02,  1.0669e-02,  8.0010e-03,  6.0000e-03,\n",
              "          4.4993e-03,  3.3740e-03,  2.5302e-03,  1.8974e-03,  1.4228e-03,\n",
              "          1.0670e-03,  8.0011e-04],\n",
              "        [ 6.5699e-01, -8.5931e-01, -7.1372e-01,  1.8858e-01,  8.0042e-01,\n",
              "          9.9603e-01,  9.4733e-01,  8.0369e-01,  6.4422e-01,  5.0115e-01,\n",
              "          3.8355e-01,  2.9092e-01,  2.1956e-01,  1.6523e-01,  1.2416e-01,\n",
              "          9.3211e-02,  6.9943e-02,  5.2468e-02,  3.9354e-02,  2.9514e-02,\n",
              "          2.2134e-02,  1.6599e-02,  1.2448e-02,  9.3345e-03,  6.9999e-03,\n",
              "          5.2492e-03,  3.9364e-03,  2.9519e-03,  2.2136e-03,  1.6600e-03,\n",
              "          1.2448e-03,  9.3346e-04],\n",
              "        [ 9.8936e-01, -2.8023e-01, -9.7726e-01, -2.2990e-01,  5.7432e-01,\n",
              "          9.4723e-01,  9.8904e-01,  8.7567e-01,  7.1736e-01,  5.6457e-01,\n",
              "          4.3485e-01,  3.3099e-01,  2.5029e-01,  1.8857e-01,  1.4178e-01,\n",
              "          1.0648e-01,  7.9915e-02,  5.9956e-02,  4.4972e-02,  3.3729e-02,\n",
              "          2.5296e-02,  1.8970e-02,  1.4226e-02,  1.0668e-02,  7.9999e-03,\n",
              "          5.9991e-03,  4.4987e-03,  3.3736e-03,  2.5298e-03,  1.8971e-03,\n",
              "          1.4226e-03,  1.0668e-03],\n",
              "        [ 4.1212e-01,  4.4919e-01, -9.3982e-01, -6.0811e-01,  2.9126e-01,\n",
              "          8.4542e-01,  9.9956e-01,  9.3210e-01,  7.8333e-01,  6.2482e-01,\n",
              "          4.8478e-01,  3.7048e-01,  2.8078e-01,  2.1181e-01,  1.5936e-01,\n",
              "          1.1973e-01,  8.9879e-02,  6.7439e-02,  5.0589e-02,  3.7944e-02,\n",
              "          2.8457e-02,  2.1341e-02,  1.6004e-02,  1.2001e-02,  8.9999e-03,\n",
              "          6.7490e-03,  5.0611e-03,  3.7953e-03,  2.8460e-03,  2.1342e-03,\n",
              "          1.6005e-03,  1.2002e-03]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "even_PE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fjmx56D25A5T",
        "outputId": "9615f471-3bc5-445e-d229-09bcd93d239e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 32])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "even_PE.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8TlRfY745hA",
        "outputId": "bfd9bd54-009a-4cb5-c682-88bffc6b7a4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
              "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
              "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
              "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
              "        [ 0.5403,  0.7318,  0.8460,  0.9124,  0.9504,  0.9720,  0.9842,  0.9911,\n",
              "          0.9950,  0.9972,  0.9984,  0.9991,  0.9995,  0.9997,  0.9998,  0.9999,\n",
              "          0.9999,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
              "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
              "        [-0.4161,  0.0709,  0.4315,  0.6649,  0.8066,  0.8896,  0.9374,  0.9646,\n",
              "          0.9801,  0.9888,  0.9937,  0.9964,  0.9980,  0.9989,  0.9994,  0.9996,\n",
              "          0.9998,  0.9999,  0.9999,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
              "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
              "        [-0.9900, -0.6279, -0.1160,  0.3010,  0.5828,  0.7574,  0.8610,  0.9210,\n",
              "          0.9553,  0.9748,  0.9858,  0.9920,  0.9955,  0.9975,  0.9986,  0.9992,\n",
              "          0.9996,  0.9997,  0.9999,  0.9999,  1.0000,  1.0000,  1.0000,  1.0000,\n",
              "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
              "        [-0.6536, -0.9899, -0.6277, -0.1157,  0.3011,  0.5829,  0.7575,  0.8611,\n",
              "          0.9211,  0.9553,  0.9748,  0.9858,  0.9920,  0.9955,  0.9975,  0.9986,\n",
              "          0.9992,  0.9996,  0.9997,  0.9999,  0.9999,  1.0000,  1.0000,  1.0000,\n",
              "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
              "        [ 0.2837, -0.8209, -0.9461, -0.5122, -0.0103,  0.3757,  0.6301,  0.7858,\n",
              "          0.8776,  0.9305,  0.9607,  0.9779,  0.9875,  0.9930,  0.9960,  0.9978,\n",
              "          0.9988,  0.9993,  0.9996,  0.9998,  0.9999,  0.9999,  1.0000,  1.0000,\n",
              "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
              "        [ 0.9602, -0.2114, -0.9731, -0.8188, -0.3208,  0.1474,  0.4828,  0.6966,\n",
              "          0.8253,  0.9005,  0.9436,  0.9682,  0.9821,  0.9899,  0.9943,  0.9968,\n",
              "          0.9982,  0.9990,  0.9994,  0.9997,  0.9998,  0.9999,  0.9999,  1.0000,\n",
              "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
              "        [ 0.7539,  0.5114, -0.7004, -0.9821, -0.5994, -0.0890,  0.3203,  0.5951,\n",
              "          0.7648,  0.8654,  0.9235,  0.9567,  0.9756,  0.9863,  0.9923,  0.9956,\n",
              "          0.9976,  0.9986,  0.9992,  0.9996,  0.9998,  0.9999,  0.9999,  1.0000,\n",
              "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
              "        [-0.1455,  0.9599, -0.2120, -0.9732, -0.8186, -0.3205,  0.1476,  0.4829,\n",
              "          0.6967,  0.8254,  0.9005,  0.9436,  0.9682,  0.9821,  0.9899,  0.9943,\n",
              "          0.9968,  0.9982,  0.9990,  0.9994,  0.9997,  0.9998,  0.9999,  0.9999,\n",
              "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
              "        [-0.9111,  0.8934,  0.3417, -0.7939, -0.9566, -0.5341, -0.0297,  0.3622,\n",
              "          0.6216,  0.7808,  0.8746,  0.9288,  0.9598,  0.9773,  0.9872,  0.9928,\n",
              "          0.9960,  0.9977,  0.9987,  0.9993,  0.9996,  0.9998,  0.9999,  0.9999,\n",
              "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "odd_PE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bazd5CSZ948R",
        "outputId": "396408c7-26b1-4268-b530-bcfa32a95d69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 32])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "odd_PE.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0n6V1nk_Pgg",
        "outputId": "0b9c0f1e-3a48-4993-a295-5634b73dd82c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 32, 2])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stacked = torch.stack([even_PE, odd_PE], dim=2)\n",
        "stacked.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJAGzwSF_fVV",
        "outputId": "62e15b26-d4b0-433d-8fd0-fc10b5e7311b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
              "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
              "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
              "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
              "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
              "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
              "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
              "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
              "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
              "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
              "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
              "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
              "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
              "        [ 8.4147e-01,  5.4030e-01,  6.8156e-01,  7.3176e-01,  5.3317e-01,\n",
              "          8.4601e-01,  4.0931e-01,  9.1240e-01,  3.1098e-01,  9.5042e-01,\n",
              "          2.3492e-01,  9.7201e-01,  1.7689e-01,  9.8423e-01,  1.3296e-01,\n",
              "          9.9112e-01,  9.9833e-02,  9.9500e-01,  7.4919e-02,  9.9719e-01,\n",
              "          5.6204e-02,  9.9842e-01,  4.2157e-02,  9.9911e-01,  3.1618e-02,\n",
              "          9.9950e-01,  2.3712e-02,  9.9972e-01,  1.7782e-02,  9.9984e-01,\n",
              "          1.3335e-02,  9.9991e-01,  9.9998e-03,  9.9995e-01,  7.4989e-03,\n",
              "          9.9997e-01,  5.6234e-03,  9.9998e-01,  4.2170e-03,  9.9999e-01,\n",
              "          3.1623e-03,  9.9999e-01,  2.3714e-03,  1.0000e+00,  1.7783e-03,\n",
              "          1.0000e+00,  1.3335e-03,  1.0000e+00,  1.0000e-03,  1.0000e+00,\n",
              "          7.4989e-04,  1.0000e+00,  5.6234e-04,  1.0000e+00,  4.2170e-04,\n",
              "          1.0000e+00,  3.1623e-04,  1.0000e+00,  2.3714e-04,  1.0000e+00,\n",
              "          1.7783e-04,  1.0000e+00,  1.3335e-04,  1.0000e+00],\n",
              "        [ 9.0930e-01, -4.1615e-01,  9.9748e-01,  7.0948e-02,  9.0213e-01,\n",
              "          4.3146e-01,  7.4690e-01,  6.6493e-01,  5.9113e-01,  8.0658e-01,\n",
              "          4.5669e-01,  8.8962e-01,  3.4821e-01,  9.3742e-01,  2.6355e-01,\n",
              "          9.6464e-01,  1.9867e-01,  9.8007e-01,  1.4942e-01,  9.8877e-01,\n",
              "          1.1223e-01,  9.9368e-01,  8.4239e-02,  9.9645e-01,  6.3203e-02,\n",
              "          9.9800e-01,  4.7410e-02,  9.9888e-01,  3.5558e-02,  9.9937e-01,\n",
              "          2.6667e-02,  9.9964e-01,  1.9999e-02,  9.9980e-01,  1.4997e-02,\n",
              "          9.9989e-01,  1.1247e-02,  9.9994e-01,  8.4338e-03,  9.9996e-01,\n",
              "          6.3245e-03,  9.9998e-01,  4.7427e-03,  9.9999e-01,  3.5566e-03,\n",
              "          9.9999e-01,  2.6670e-03,  1.0000e+00,  2.0000e-03,  1.0000e+00,\n",
              "          1.4998e-03,  1.0000e+00,  1.1247e-03,  1.0000e+00,  8.4339e-04,\n",
              "          1.0000e+00,  6.3246e-04,  1.0000e+00,  4.7427e-04,  1.0000e+00,\n",
              "          3.5566e-04,  1.0000e+00,  2.6670e-04,  1.0000e+00],\n",
              "        [ 1.4112e-01, -9.8999e-01,  7.7827e-01, -6.2793e-01,  9.9325e-01,\n",
              "         -1.1597e-01,  9.5363e-01,  3.0097e-01,  8.1265e-01,  5.8275e-01,\n",
              "          6.5290e-01,  7.5744e-01,  5.0854e-01,  8.6104e-01,  3.8947e-01,\n",
              "          9.2104e-01,  2.9552e-01,  9.5534e-01,  2.2308e-01,  9.7480e-01,\n",
              "          1.6790e-01,  9.8580e-01,  1.2617e-01,  9.9201e-01,  9.4726e-02,\n",
              "          9.9550e-01,  7.1081e-02,  9.9747e-01,  5.3323e-02,  9.9858e-01,\n",
              "          3.9995e-02,  9.9920e-01,  2.9995e-02,  9.9955e-01,  2.2495e-02,\n",
              "          9.9975e-01,  1.6869e-02,  9.9986e-01,  1.2651e-02,  9.9992e-01,\n",
              "          9.4867e-03,  9.9995e-01,  7.1141e-03,  9.9997e-01,  5.3348e-03,\n",
              "          9.9999e-01,  4.0006e-03,  9.9999e-01,  3.0000e-03,  1.0000e+00,\n",
              "          2.2497e-03,  1.0000e+00,  1.6870e-03,  1.0000e+00,  1.2651e-03,\n",
              "          1.0000e+00,  9.4868e-04,  1.0000e+00,  7.1141e-04,  1.0000e+00,\n",
              "          5.3348e-04,  1.0000e+00,  4.0006e-04,  1.0000e+00],\n",
              "        [-7.5680e-01, -6.5364e-01,  1.4154e-01, -9.8993e-01,  7.7847e-01,\n",
              "         -6.2768e-01,  9.9328e-01, -1.1573e-01,  9.5358e-01,  3.0114e-01,\n",
              "          8.1257e-01,  5.8286e-01,  6.5283e-01,  7.5751e-01,  5.0847e-01,\n",
              "          8.6108e-01,  3.8942e-01,  9.2106e-01,  2.9548e-01,  9.5535e-01,\n",
              "          2.2304e-01,  9.7481e-01,  1.6788e-01,  9.8581e-01,  1.2615e-01,\n",
              "          9.9201e-01,  9.4713e-02,  9.9550e-01,  7.1071e-02,  9.9747e-01,\n",
              "          5.3316e-02,  9.9858e-01,  3.9989e-02,  9.9920e-01,  2.9991e-02,\n",
              "          9.9955e-01,  2.2492e-02,  9.9975e-01,  1.6867e-02,  9.9986e-01,\n",
              "          1.2649e-02,  9.9992e-01,  9.4854e-03,  9.9995e-01,  7.1131e-03,\n",
              "          9.9997e-01,  5.3341e-03,  9.9999e-01,  4.0000e-03,  9.9999e-01,\n",
              "          2.9996e-03,  1.0000e+00,  2.2494e-03,  1.0000e+00,  1.6868e-03,\n",
              "          1.0000e+00,  1.2649e-03,  1.0000e+00,  9.4855e-04,  1.0000e+00,\n",
              "          7.1131e-04,  1.0000e+00,  5.3341e-04,  1.0000e+00],\n",
              "        [-9.5892e-01,  2.8366e-01, -5.7113e-01, -8.2086e-01,  3.2394e-01,\n",
              "         -9.4608e-01,  8.5890e-01, -5.1215e-01,  9.9995e-01, -1.0342e-02,\n",
              "          9.2676e-01,  3.7566e-01,  7.7653e-01,  6.3008e-01,  6.1844e-01,\n",
              "          7.8583e-01,  4.7943e-01,  8.7758e-01,  3.6622e-01,  9.3053e-01,\n",
              "          2.7748e-01,  9.6073e-01,  2.0929e-01,  9.7785e-01,  1.5746e-01,\n",
              "          9.8753e-01,  1.1829e-01,  9.9298e-01,  8.8797e-02,  9.9605e-01,\n",
              "          6.6627e-02,  9.9778e-01,  4.9979e-02,  9.9875e-01,  3.7486e-02,\n",
              "          9.9930e-01,  2.8113e-02,  9.9960e-01,  2.1083e-02,  9.9978e-01,\n",
              "          1.5811e-02,  9.9988e-01,  1.1857e-02,  9.9993e-01,  8.8913e-03,\n",
              "          9.9996e-01,  6.6676e-03,  9.9998e-01,  5.0000e-03,  9.9999e-01,\n",
              "          3.7495e-03,  9.9999e-01,  2.8117e-03,  1.0000e+00,  2.1085e-03,\n",
              "          1.0000e+00,  1.5811e-03,  1.0000e+00,  1.1857e-03,  1.0000e+00,\n",
              "          8.8914e-04,  1.0000e+00,  6.6676e-04,  1.0000e+00],\n",
              "        [-2.7942e-01,  9.6017e-01, -9.7740e-01, -2.1142e-01, -2.3037e-01,\n",
              "         -9.7310e-01,  5.7403e-01, -8.1884e-01,  9.4715e-01, -3.2080e-01,\n",
              "          9.8907e-01,  1.4743e-01,  8.7574e-01,  4.8278e-01,  7.1743e-01,\n",
              "          6.9663e-01,  5.6464e-01,  8.2534e-01,  4.3491e-01,  9.0047e-01,\n",
              "          3.3104e-01,  9.4362e-01,  2.5033e-01,  9.6816e-01,  1.8860e-01,\n",
              "          9.8205e-01,  1.4180e-01,  9.8989e-01,  1.0649e-01,  9.9431e-01,\n",
              "          7.9926e-02,  9.9680e-01,  5.9964e-02,  9.9820e-01,  4.4978e-02,\n",
              "          9.9899e-01,  3.3734e-02,  9.9943e-01,  2.5299e-02,  9.9968e-01,\n",
              "          1.8973e-02,  9.9982e-01,  1.4228e-02,  9.9990e-01,  1.0669e-02,\n",
              "          9.9994e-01,  8.0010e-03,  9.9997e-01,  6.0000e-03,  9.9998e-01,\n",
              "          4.4993e-03,  9.9999e-01,  3.3740e-03,  9.9999e-01,  2.5302e-03,\n",
              "          1.0000e+00,  1.8974e-03,  1.0000e+00,  1.4228e-03,  1.0000e+00,\n",
              "          1.0670e-03,  1.0000e+00,  8.0011e-04,  1.0000e+00],\n",
              "        [ 6.5699e-01,  7.5390e-01, -8.5931e-01,  5.1145e-01, -7.1372e-01,\n",
              "         -7.0043e-01,  1.8858e-01, -9.8206e-01,  8.0042e-01, -5.9944e-01,\n",
              "          9.9603e-01, -8.9047e-02,  9.4733e-01,  3.2026e-01,  8.0369e-01,\n",
              "          5.9505e-01,  6.4422e-01,  7.6484e-01,  5.0115e-01,  8.6536e-01,\n",
              "          3.8355e-01,  9.2352e-01,  2.9092e-01,  9.5675e-01,  2.1956e-01,\n",
              "          9.7560e-01,  1.6523e-01,  9.8625e-01,  1.2416e-01,  9.9226e-01,\n",
              "          9.3211e-02,  9.9565e-01,  6.9943e-02,  9.9755e-01,  5.2468e-02,\n",
              "          9.9862e-01,  3.9354e-02,  9.9923e-01,  2.9514e-02,  9.9956e-01,\n",
              "          2.2134e-02,  9.9976e-01,  1.6599e-02,  9.9986e-01,  1.2448e-02,\n",
              "          9.9992e-01,  9.3345e-03,  9.9996e-01,  6.9999e-03,  9.9998e-01,\n",
              "          5.2492e-03,  9.9999e-01,  3.9364e-03,  9.9999e-01,  2.9519e-03,\n",
              "          1.0000e+00,  2.2136e-03,  1.0000e+00,  1.6600e-03,  1.0000e+00,\n",
              "          1.2448e-03,  1.0000e+00,  9.3346e-04,  1.0000e+00],\n",
              "        [ 9.8936e-01, -1.4550e-01, -2.8023e-01,  9.5993e-01, -9.7726e-01,\n",
              "         -2.1204e-01, -2.2990e-01, -9.7321e-01,  5.7432e-01, -8.1863e-01,\n",
              "          9.4723e-01, -3.2054e-01,  9.8904e-01,  1.4763e-01,  8.7567e-01,\n",
              "          4.8291e-01,  7.1736e-01,  6.9671e-01,  5.6457e-01,  8.2538e-01,\n",
              "          4.3485e-01,  9.0050e-01,  3.3099e-01,  9.4363e-01,  2.5029e-01,\n",
              "          9.6817e-01,  1.8857e-01,  9.8206e-01,  1.4178e-01,  9.8990e-01,\n",
              "          1.0648e-01,  9.9431e-01,  7.9915e-02,  9.9680e-01,  5.9956e-02,\n",
              "          9.9820e-01,  4.4972e-02,  9.9899e-01,  3.3729e-02,  9.9943e-01,\n",
              "          2.5296e-02,  9.9968e-01,  1.8970e-02,  9.9982e-01,  1.4226e-02,\n",
              "          9.9990e-01,  1.0668e-02,  9.9994e-01,  7.9999e-03,  9.9997e-01,\n",
              "          5.9991e-03,  9.9998e-01,  4.4987e-03,  9.9999e-01,  3.3736e-03,\n",
              "          9.9999e-01,  2.5298e-03,  1.0000e+00,  1.8971e-03,  1.0000e+00,\n",
              "          1.4226e-03,  1.0000e+00,  1.0668e-03,  1.0000e+00],\n",
              "        [ 4.1212e-01, -9.1113e-01,  4.4919e-01,  8.9343e-01, -9.3982e-01,\n",
              "          3.4166e-01, -6.0811e-01, -7.9385e-01,  2.9126e-01, -9.5664e-01,\n",
              "          8.4542e-01, -5.3410e-01,  9.9956e-01, -2.9651e-02,  9.3210e-01,\n",
              "          3.6220e-01,  7.8333e-01,  6.2161e-01,  6.2482e-01,  7.8077e-01,\n",
              "          4.8478e-01,  8.7464e-01,  3.7048e-01,  9.2884e-01,  2.8078e-01,\n",
              "          9.5977e-01,  2.1181e-01,  9.7731e-01,  1.5936e-01,  9.8722e-01,\n",
              "          1.1973e-01,  9.9281e-01,  8.9879e-02,  9.9595e-01,  6.7439e-02,\n",
              "          9.9772e-01,  5.0589e-02,  9.9872e-01,  3.7944e-02,  9.9928e-01,\n",
              "          2.8457e-02,  9.9960e-01,  2.1341e-02,  9.9977e-01,  1.6004e-02,\n",
              "          9.9987e-01,  1.2001e-02,  9.9993e-01,  8.9999e-03,  9.9996e-01,\n",
              "          6.7490e-03,  9.9998e-01,  5.0611e-03,  9.9999e-01,  3.7953e-03,\n",
              "          9.9999e-01,  2.8460e-03,  1.0000e+00,  2.1342e-03,  1.0000e+00,\n",
              "          1.6005e-03,  1.0000e+00,  1.2002e-03,  1.0000e+00]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
        "PE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Liidl3ggt0wK"
      },
      "source": [
        "## Class\n",
        "\n",
        "Let's combine all the code above into a cute class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "E1G1ziOa6SdZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, max_sequence_length):\n",
        "        super().__init__()\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self):\n",
        "        even_i = torch.arange(0, self.d_model, 2).float()\n",
        "        denominator = torch.pow(10000, even_i/self.d_model)\n",
        "        position = torch.arange(self.max_sequence_length).reshape(self.max_sequence_length, 1)\n",
        "        even_PE = torch.sin(position / denominator)\n",
        "        odd_PE = torch.cos(position / denominator)\n",
        "        stacked = torch.stack([even_PE, odd_PE], dim=2)\n",
        "        PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
        "        return PE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENHY3b-BDgL9",
        "outputId": "6413d8c5-7fbd-48b4-dfd6-bbae0396bd0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
              "        [ 0.8415,  0.5403,  0.0464,  0.9989,  0.0022,  1.0000],\n",
              "        [ 0.9093, -0.4161,  0.0927,  0.9957,  0.0043,  1.0000],\n",
              "        [ 0.1411, -0.9900,  0.1388,  0.9903,  0.0065,  1.0000],\n",
              "        [-0.7568, -0.6536,  0.1846,  0.9828,  0.0086,  1.0000],\n",
              "        [-0.9589,  0.2837,  0.2300,  0.9732,  0.0108,  0.9999],\n",
              "        [-0.2794,  0.9602,  0.2749,  0.9615,  0.0129,  0.9999],\n",
              "        [ 0.6570,  0.7539,  0.3192,  0.9477,  0.0151,  0.9999],\n",
              "        [ 0.9894, -0.1455,  0.3629,  0.9318,  0.0172,  0.9999],\n",
              "        [ 0.4121, -0.9111,  0.4057,  0.9140,  0.0194,  0.9998]])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pe = PositionalEncoding(d_model=6, max_sequence_length=10)\n",
        "pe.forward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjPIbLcBt6l4"
      },
      "source": [
        "Happy Coding!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
